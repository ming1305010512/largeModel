[TOC]

下面我从**“它是什么 → 怎么建 → 内部算法（HNSW）→ 怎么查 → 参数怎么调 → 常见坑”**，把 **Neo4j 的向量索引（Vector Index）**系统地讲清楚。你已经有 HNSW 和 Neo4jVector 的基础，这里我会直接对齐到 **Neo4j 实现层**。

> 先给一句话结论：
> **Neo4j 的向量索引 = 在 Neo4j 内部，把节点的向量属性用 HNSW 建索引，并通过 Cypher 原生 API 做 ANN 搜索。**

------

## 一、Neo4j 向量索引是什么

**向量索引**是一种**专门为“向量相似度搜索”设计的索引类型**，用于回答：

> 给定一个向量，在所有节点向量中找 **最相似的 K 个**。

它与 B-tree / Fulltext 索引不同点在于：

| 索引类型   | 解决的问题          |
| ---------- | ------------------- |
| B-tree     | 精确值 / 范围       |
| Fulltext   | 关键词匹配          |
| **Vector** | **语义相似（ANN）** |

------

## 二、向量索引建在“哪里”

Neo4j 的向量索引是 **“节点级索引”**：

- 索引对象：某个 **label**
- 索引字段：一个 **Float 数组属性**

例如：

```cypher
(:Document {
  text: "Apple iPhone 15 Pro",
  embedding: [0.012, -0.23, ...]   // 向量
})
```

索引就建在 `:Document(embedding)` 上。

------

## 三、如何创建向量索引（标准写法）

```cypher
CREATE VECTOR INDEX doc_embedding_index
FOR (d:Document)
ON (d.embedding)
OPTIONS {
  indexConfig: {
    `vector.dimensions`: 384,
    `vector.similarity_function`: 'cosine'
  }
}
```

### 两个**必须项**

1️⃣ **vector.dimensions**

- 必须和 embedding 模型输出维度 **完全一致**
- 384 / 768 / 1024 …

2️⃣ **vector.similarity_function**

- `'cosine'`（最常用，sentence-transformers / BGE / m3e）
- `'l2'`
- `'dot'`

> ⚠️ 建完索引后 **不能改维度/相似度**，只能删了重建。

------

## 四、Neo4j 向量索引的底层算法：HNSW

Neo4j 的向量索引**底层算法是 HNSW**（Hierarchical Navigable Small World）。

你之前问的 `efSearch`、Candidate Set，本质都发生在 **Neo4j 内部这层**。

Neo4j 的角色是：

- 负责 **索引构建**
- 负责 **搜索调度**
- 你通过 Cypher 只能“用”，**不能直接控制每一步**

------

## 五、向量索引是怎么被“用”的（查询）

Neo4j 提供了一个 **专用过程**：

```cypher
CALL db.index.vector.queryNodes(
  'doc_embedding_index',
  5,
  $query_embedding
)
YIELD node, score
RETURN node, score
```

### 参数含义

| 参数             | 含义             |
| ---------------- | ---------------- |
| 索引名           | 你创建的向量索引 |
| 5                | topK             |
| $query_embedding | 查询向量         |

返回：

- `node`：命中的节点
- `score`：相似度（cosine 时越大越相似）

------

## 六、Neo4jVector / LangChain 实际就是在调这个

你写的：

```python
Neo4jVector.similarity_search(query, k=5)
```

内部就是：

1. embedding(query)
2. 拼 Cypher
3. 调 `db.index.vector.queryNodes`
4. 把 node → Document

------

## 七、HNSW 的关键参数：Neo4j 能不能调？

### 能调的（有限）

在 **部分版本**，Neo4j 支持在索引 OPTIONS 里配置 HNSW 参数（不同版本支持度略有差异）：

常见概念（你要理解，但不一定都能显式设置）：

| 参数           | 作用               |
| -------------- | ------------------ |
| M              | 每个节点最大邻居数 |
| efConstruction | 建索引时搜索宽度   |
| efSearch       | 查询时搜索宽度     |

> ⚠️ **大多数情况下**：
>
> - `efConstruction` / `M` 由 Neo4j 默认给
> - `efSearch` 在查询时由内部策略控制
> - Neo4j **不鼓励用户像 hnswlib 那样细调**

工程建议：
👉 **把精力放在 embedding 质量 + topK + 后续图查询**，而不是死磕 efSearch。

------

## 八、向量索引 ≠ 图查询（重要边界）

向量索引**只做一件事**：

> 给我一个向量，返回最相似的节点。

它**不会**：

- 沿关系扩展
- 做路径搜索
- 推理

典型正确用法是 **两段式**：

```text
向量索引：召回候选节点（topK）
↓
图查询：基于候选节点做关系推理 / 聚合
```

------

## 九、常见坑（你很可能会再踩）

### ❌ 坑 1：模型换了，索引没换

- 维度不一致 → 查询直接报错或结果异常
- **模型一换，索引必删重建**

------

### ❌ 坑 2：embedding 属性有 None / 空

- 索引构建阶段就会失败
- 或查询时行为异常

👉 上游必须保证：

```text
embedding: List[float] 且长度固定
```

------

### ❌ 坑 3：相似度函数选错

- cosine embedding + L2 索引
  → 排名会“看起来随机”

------

### ❌ 坑 4：把向量索引当成“最终答案”

- 它只是召回
- 精确逻辑必须靠 Cypher

------

## 十、和 FAISS / Milvus 的对比（工程取舍）

| 维度       | Neo4j 向量索引 | FAISS |
| ---------- | -------------- | ----- |
| 算法       | HNSW           | 多种  |
| 事务       | ✅              | ❌     |
| 图关系     | ✅              | ❌     |
| 可调性     | 低             | 高    |
| 性能       | 中             | 高    |
| 运维复杂度 | 低             | 中    |

👉 **你这个“图谱 + 语义”的项目，Neo4j 向量索引是非常合理的选择。**

------

## 十一、一句话工程总结（给你记）

> **Neo4j 的向量索引，是把 HNSW 嵌进图数据库，让“语义召回”和“图关系推理”在同一个系统里完成。**

