整个项目按同一个底座fnlp/bart-base-chinese模型来实现分类和摘要抽取，并且

分类：只用 BART 的 encoder + mean pooling + 分类头

摘要：用 **BART seq2seq 微调**（标准）

数据预处理：**CSV 清洗/去空/去重复/长度裁剪/分层切分（分类）**

训练验证：分类 Accuracy+MacroF1；摘要 ROUGE-1/2/L（jieba 分词）

预测：单条/批量

API：FastAPI 一个接口同时返回分类+摘要



## 安装依赖

```
pip install -U transformers datasets evaluate rouge_score jieba accelerate sentencepiece fastapi uvicorn pandas scikit-learn

```

