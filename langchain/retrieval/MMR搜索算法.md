[TOC]

MMR 一般指 **Maximal Marginal Relevance（最大边际相关性）**：一种用在检索/推荐/RAG 的“**相关性 vs 多样性**”折中算法。它解决的问题很具体：

> 向量检索 TopK 往往会返回一堆“彼此很像”的内容（冗余）。
> MMR 会在“跟问题相关”前提下，**尽量挑彼此不重复**的一组结果。

------

## 1) 核心思想

MMR 不是一次性排序完就取 TopK，而是 **贪心式逐个挑选**：

- 先挑最相关的 1 个
- 之后每次挑“既相关、又不和已选结果太相似”的那个
- 直到选满 k 个

------

## 2) 公式长什么样

设：

- 查询向量：(q)
- 候选文档集合：(R)
- 已选集合：(S)
- 相似度函数：(\mathrm{sim}(\cdot,\cdot))（常用余弦相似度）
- 权衡系数：(\lambda \in [0,1])

每一步从未选集合 (R\setminus S) 里选一个 (d) 使得：

[
\mathrm{MMR}(d) = \lambda\cdot \mathrm{sim}(d, q) ;-; (1-\lambda)\cdot \max_{s\in S}\mathrm{sim}(d, s)
]

- 第一项：**相关性**（越大越好）
- 第二项：**冗余惩罚**（与已选最相似的那个越像，扣分越多）
- (\lambda) 越大：越偏“相关性”
- (\lambda) 越小：越偏“多样性/去重”

------

## 3) 一个直觉例子（为什么 TopK 会“挤”）

你问：“糖尿病早餐怎么搭配？”

向量 Top10 可能都是：

- “燕麦 + 牛奶”
- “燕麦怎么吃”
- “燕麦控糖”
- “燕麦GI值”
  ……（很相关，但全是燕麦）

MMR 会更倾向于挑成：

- 燕麦类 1 篇（代表）
- 全麦馒头/包子搭配 1 篇
- 红薯怎么搭配蛋白质 1 篇
- 汤粉/米线低 GI 改造 1 篇
  这样你拿到的是“覆盖面更广”的证据集合，RAG 生成质量往往更稳。

------

## 4) MMR 的关键参数怎么选

### (\lambda)（相关 vs 多样）

- **0.8 ~ 0.95**：更像普通相似度 TopK，只做轻度去重（最常用）
- **0.5 ~ 0.7**：多样性明显增强，适合“综述型问题/想要覆盖面”
- **< 0.5**：可能开始牺牲相关性，容易选到“有点跑题但很不重复”的东西

### `fetch_k`（先取多少候选再做 MMR）

MMR 一般先从向量库“粗召回”一批候选（fetch_k），然后在这批里挑 top_k。

- `fetch_k` 太小：候选本来就很同质，MMR也没空间挑多样
- 常见经验：`fetch_k = 20~100`，`top_k = 5~20`（看库大小和问题复杂度）

------

## 5) MMR 在 RAG 里的典型用法

你在 RAG 检索阶段常见三种策略：

1. **纯相似度 TopK**
   - 优点：相关性强
   - 缺点：重复多、证据覆盖窄
2. **MMR**
   - 优点：相关性不错 + 覆盖面更广、减少重复片段
   - 缺点：参数不当会引入“略不相关”的块
3. **Hybrid（BM25 + 向量）+ MMR**
   - 更稳：先混合召回，再 MMR 去冗余（工程上很常见）

------

## 6) 在 LangChain 里你会看到的接口（概念对应）

很多向量库/检索器会提供：

- `search_type="mmr"`
- `k`（top_k）
- `fetch_k`
- `lambda_mult`（就是 (\lambda)）

例如你可能会见到类似配置（不同 VectorStore 名字略有差别）：

- `as_retriever(search_type="mmr", search_kwargs={"k": 8, "fetch_k": 40, "lambda_mult": 0.8})`

------

## 7) 什么时候强烈建议用 MMR

- 你发现检索结果**重复很严重**（同一段话不同切块反复出现）
- 问题是“**总结/对比/给方案**”这类，需要覆盖多个方面
- chunk 切得比较细（重叠多），TopK 很容易扎堆

不太建议用的情况：

- 问题非常精确（例如查一个具体定义/单条事实），此时纯 TopK 可能更干净
- 你更在意“最相关的证据”而不是“覆盖面”（比如法律条文精确引用）。