[TOC]



# 一、特征选择的包裹法

包裹法（**Wrapper Method**）是一种特征选择方法，它将特征选择过程嵌套在模型训练过程中，通过模型性能（如准确率、F1 分数等）来评估特征子集的优劣。

[参考文档](https://chatgpt.com/g/g-p-68f37437b74c8191a4f2f60101bcf8c3-da-mo-xing-xue-xi/c/6900e0f3-f13c-8321-9bc5-bb7a66f44568)

------

## 🧠 本质思想

> **特征子集的优劣，取决于模型的最终表现**
>  包裹法不像过滤法那样独立于模型进行评分，而是将特征组合喂入模型训练，评估其表现好坏，从而决定保留哪些特征。



------

## 📦 工作流程

1. **选择一个模型**（如逻辑回归、SVM、决策树等）
2. **初始化特征子集**（可以为空集、全特征集或随机子集）
3. **按策略搜索特征子集**
   - 加法策略（向前选择）
   - 减法策略（向后剔除）
   - 穷举或启发式搜索（递归特征消除、遗传算法等）
4. **训练模型并评估性能**（如交叉验证准确率）
5. **根据性能决定是否保留特征**
6. **迭代直到满足停止条件**

------

## 🔍 常见策略

| 策略                             | 描述                                       |
| -------------------------------- | ------------------------------------------ |
| 向前选择（Forward Selection）    | 从空集开始，每次加入一个最能提升性能的特征 |
| 向后剔除（Backward Elimination） | 从全特征集开始，每次移除最不影响性能的特征 |
| 递归特征消除（RFE）              | 每轮训练模型，剔除权重最小的特征           |
| 遗传算法/模拟退火                | 用搜索算法优化特征组合                     |

------

## 🧪 优点

- 考虑了特征之间的**相互作用**
- 精度通常高于过滤法
- 与具体模型紧密结合，结果更贴近真实性能

------

## ⚠️ 缺点

- **计算成本高**（每个特征组合都要训练模型）
- **不易并行化**
- 可能会过拟合（尤其是在小样本时）

------

## 💡 示例（向前选择）

假设我们有 5 个特征：

```
特征集：{A, B, C, D, E}
```

1. 初始化：空集 {}
2. 尝试每个单特征：训练模型后得到准确率：
   - {A} → 0.74
   - {B} → 0.78 ✅
   - {C} → 0.70
   - ...
3. 选择 B，当前子集 = {B}
4. 加入剩余中最优的一个：
   - {B, A} → 0.81 ✅
   - {B, C} → 0.79
   - ...
5. 当前子集 = {B, A}，继续直到性能不再提升或满足停止条件。

------

## 📦 在 sklearn 中使用包裹法

### 示例：`RFE`（递归特征消除）

```python
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
rfe = RFE(model, n_features_to_select=5)
X_new = rfe.fit_transform(X, y)

# 查看选择的特征
print(rfe.support_)
print(rfe.ranking_)
```

------

## ✅ 总结

| 属性             | 描述                       |
| ---------------- | -------------------------- |
| 是否依赖模型     | ✅ 是                       |
| 是否考虑特征交互 | ✅ 是                       |
| 运算速度         | ❌ 慢（需反复训练模型）     |
| 是否易过拟合     | ⚠️ 可能，尤其是样本小的时候 |

包裹法适用于你希望以模型效果为核心标准进行精细特征选择的情况，尤其适合在特征维度不高但你非常在意模型性能的任务中使用。若你还想了解与之对比的**过滤法和嵌入法**，我可以继续补充。





# 二、ROC曲线，阈值 = 0 时，FPR = 1，TPR = 1，阈值 = 1 时，FPR = 0，TPR = 0

------

## 🧠 回顾基本概念：

你有一组模型输出的**预测概率分数**（如：0.1、0.3、0.95、0.6），再设置一个 **判别阈值**：

- 如果预测分数 ≥ 阈值 → 预测为正类（1）
- 否则 → 预测为负类（0）

ROC 曲线就是在**不断改变阈值**时，记录下的：

- TPR = 真正例率（召回率） = TP / (TP + FN)
- FPR = 假正例率 = FP / (FP + TN)

------

## ✅ 那当阈值 = 0 时会发生什么？

**预测条件：所有得分 ≥ 0 都判成正例**

但所有模型输出概率本来都是 ≥ 0 的（比如从 sigmoid 或 softmax 出来的），所以：

👉 **所有样本都会被预测成正例**

于是：

- 所有真正的正样本都预测对了（TP 全部被命中） → **TPR = 1**
- 所有负样本也被误判为正例（FP 全部出现） → **FPR = 1**

------

## ✅ 那阈值 = 1 时呢？

**预测条件：只有得分 ≥ 1 才判为正例**

但模型输出概率最大也就接近 1（不会真正等于 1），所以：

👉 **没有任何样本能通过这个条件**，全都预测为负类

于是：

- 没有真正的正例被预测成正例（TP = 0） → **TPR = 0**
- 没有负例被误判为正（FP = 0） → **FPR = 0**

------

## 🧪 举个小例子（你秒懂）

```python
y_true    = [0, 0, 1, 1]                 # 实际标签
y_score   = [0.1, 0.4, 0.35, 0.8]        # 模型输出概率
```

用不同阈值预测：

### 阈值 = 0：

- 所有分数 ≥ 0 → 全都预测为 1
- $$y_pred = [1, 1, 1, 1]$$
- $$TP = 2, FN = 0 → TPR = 1.0$$
- $$FP = 2, TN = 0 → FPR = 1.0$$

### 阈值 = 1：

- $$所有分数 < 1 → 全都预测为 0$$
- $$y_pred = [0, 0, 0, 0]$$
- $$TP = 0, FN = 2 → TPR = 0.0$$
- $$FP = 0, TN = 2 → FPR = 0.0$$

------

## ✅ ROC 曲线的两个端点

| 阈值 | y_pred 全为 | FPR  | TPR  |
| ---- | ----------- | ---- | ---- |
| 0    | 全是 1      | 1    | 1    |
| 1    | 全是 0      | 0    | 0    |

所以 ROC 曲线永远是从 (0, 0) 起点，跑到 (1, 1) 终点，**往左上角拐得越快越好！**

------

## ✅ 总结重点

| 现象                               | 原因                                  |
| ---------------------------------- | ------------------------------------- |
| 阈值 = 0 时，FPR = 1，TPR = 1      | 所有样本都预测为正类，TP 和 FP 都最大 |
| 阈值 = 1 时，FPR = 0，TPR = 0      | 所有样本都预测为负类，TP 和 FP 都为 0 |
| ROC 曲线起点是 (0,0)，终点是 (1,1) | 来自这两个极端阈值点                  |

------

如果你需要我用图形 + 模拟数据帮你画出这几个点对应的 ROC 曲线转折过程，或者你现在有真实模型输出，我也可以帮你画完整图哟 🎯

要不要我们用你数据来练一个实际的？